{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f7e17f61-97f5-4503-bc62-e4babc7efa43",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "from langchain_ollama import ChatOllama\n",
    "from tqdm import tqdm\n",
    "import subprocess\n",
    "import psutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "6adce521-d744-41d5-b333-7b046b5e06e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "questions_df = pd.read_csv(\"questions.csv\")\n",
    "questions = questions_df[\"questions\"].tolist()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7260ff12-ddbe-4506-a773-b78058639d8d",
   "metadata": {},
   "source": [
    "models = [\"phi4\", \"deepseek-r1:32b\", \"deepseek-r1:70b\", \"gemma3:27b\", \"qwen2.5:72b\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b4c97426-850d-4298-9d0f-c474c1b96ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\"qwen2.5:72b\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "52835ec9-38e1-47d5-943a-26d9096f2ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gpu_memory_usage():\n",
    "    result = subprocess.run(\n",
    "        ['nvidia-smi', '--query-gpu=memory.used,memory.total', '--format=csv,noheader,nounits'],\n",
    "        stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True\n",
    "    )\n",
    "    # Чтение результата\n",
    "    gpu_usage = result.stdout.strip().split('\\n')\n",
    "    used, total = map(int, gpu_usage[0].split(', '))\n",
    "    return used, total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b7616642-ff8d-47b4-ac34-08fa044ecb2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, questions, model_name):\n",
    "    total_time = 0\n",
    "    memory_usage = []\n",
    "\n",
    "    # Создаем DataFrame для записи результатов\n",
    "    columns = [\n",
    "        \"question\", \"answer\", \"time_taken\", \n",
    "        \"gpu_memory_before\", \"gpu_memory_after\", \"gpu_memory_delta\"\n",
    "    ]\n",
    "    model_df = pd.DataFrame(columns=columns)\n",
    "\n",
    "    # Инициализируем файл для результатов\n",
    "    model_df.to_csv(f\"{model_name}_results.csv\", mode='w', header=True, index=False)\n",
    "\n",
    "    # Начинаем тестирование\n",
    "    for question in tqdm(questions):\n",
    "        # Засекаем время\n",
    "        start_time = time.time()\n",
    "\n",
    "        # Получаем использование видеопамяти до запроса\n",
    "        gpu_used_before, gpu_total = get_gpu_memory_usage()\n",
    "\n",
    "        # Запрос к модели\n",
    "        print(question)\n",
    "        response = model.invoke(question)\n",
    "        print(response)\n",
    "\n",
    "        # Засекаем время окончания\n",
    "        end_time = time.time()\n",
    "        elapsed_time = end_time - start_time\n",
    "        total_time += elapsed_time\n",
    "\n",
    "        # Получаем использование видеопамяти после запроса\n",
    "        gpu_used_after, _ = get_gpu_memory_usage()\n",
    "\n",
    "        # Создаем строку результата для текущего вопроса\n",
    "        result = {\n",
    "            \"question\": question,\n",
    "            \"answer\": response,\n",
    "            \"time_taken\": elapsed_time,\n",
    "            \"gpu_memory_before\": gpu_used_before,\n",
    "            \"gpu_memory_after\": gpu_used_after,\n",
    "            \"gpu_memory_delta\": gpu_used_after - gpu_used_before\n",
    "        }\n",
    "\n",
    "        # Добавляем строку в DataFrame\n",
    "        model_df = model_df.append(result, ignore_index=True)\n",
    "\n",
    "        # Записываем данные в CSV файл сразу после добавления ответа\n",
    "        model_df.to_csv(f\"{model_name}_results.csv\", mode='a', header=False, index=False)\n",
    "\n",
    "        # Добавляем информацию о потреблении ресурсов\n",
    "        memory_usage.append({\n",
    "            \"time\": elapsed_time,\n",
    "            \"gpu_memory_before\": gpu_used_before,\n",
    "            \"gpu_memory_after\": gpu_used_after,\n",
    "            \"gpu_memory_delta\": gpu_used_after - gpu_used_before,\n",
    "            \"cpu_usage\": psutil.cpu_percent(interval=1),  # Загрузка CPU\n",
    "            \"ram_usage\": psutil.virtual_memory().percent  # Использование RAM\n",
    "        })\n",
    "\n",
    "    # Сохраняем данные по использованию ресурсов\n",
    "    resource_df = pd.DataFrame(memory_usage)\n",
    "    resource_df.to_csv(f\"{model_name}_resources.csv\", index=False)\n",
    "\n",
    "    return total_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfae8106-9aac-49ab-b048-7d96f3730b9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Тестирование модели: qwen2.5:72b\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                    | 0/51 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Что такое искусственный интеллект?\n"
     ]
    }
   ],
   "source": [
    "# Словарь для хранения общего времени\n",
    "total_time_all_models = {}\n",
    "\n",
    "# Словарь для записи общего времени в CSV\n",
    "overall_times = []\n",
    "\n",
    "# Тестируем все модели\n",
    "for model in models:\n",
    "    print(f\"Тестирование модели: {model}\")\n",
    "    llm_model = ChatOllama(model=model)\n",
    "    \n",
    "    total_time = test_model(llm_model, questions, model)\n",
    "    total_time_all_models[model] = total_time\n",
    "    overall_times.append({\n",
    "        \"model\": model,\n",
    "        \"total_time\": total_time\n",
    "    })\n",
    "    print(f\"Общее время для модели {model}: {total_time} секунд\")\n",
    "\n",
    "# Выводим общее время на все вопросы\n",
    "total_time_overall = sum(total_time_all_models.values())\n",
    "print(f\"Общее время на все вопросы для всех моделей: {total_time_overall} секунд\")\n",
    "\n",
    "# Сохраняем общее время в файл\n",
    "overall_times_df = pd.DataFrame(overall_times)\n",
    "overall_times_df.to_csv(\"overall_times.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12e38960-34ee-4ad9-9d12-c4f98e77c061",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b11f470-a693-448f-883f-2f2389c89994",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
