{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f7e17f61-97f5-4503-bc62-e4babc7efa43",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "from langchain_ollama import ChatOllama\n",
    "from tqdm import tqdm\n",
    "import subprocess\n",
    "import psutil\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6adce521-d744-41d5-b333-7b046b5e06e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "questions_df = pd.read_csv(\"questions.csv\")\n",
    "questions = questions_df[\"questions\"].tolist()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "567be501-ca7f-43c8-9c61-deb5bf35d6ae",
   "metadata": {},
   "source": [
    "models = [\"phi4\", \"deepseek-r1:32b\", \"deepseek-r1:70b\", \"gemma3:27b\", \"qwen2.5:32b\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c2087738-4f4f-41df-a704-3e408daccd8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\"qwen2.5:32b\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "392b3779-c339-4ca5-84fa-1d8759181839",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rocm_memory_usage():\n",
    "    try:\n",
    "        result = subprocess.run([\"rocm-smi\", \"--showmemuse\", \"--json\"], capture_output=True, text=True, check=True)\n",
    "        data = json.loads(result.stdout)\n",
    "        gpu_memory_usage = data[\"card0\"][\"GPU Memory Allocated (VRAM%)\"]\n",
    "        return int(gpu_memory_usage)\n",
    "    except Exception as e:\n",
    "        print(f\"Ошибка: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b7616642-ff8d-47b4-ac34-08fa044ecb2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, questions, model_name):\n",
    "    total_time = 0\n",
    "    memory_usage = []\n",
    "\n",
    "    columns = [\n",
    "        \"question\", \"answer\", \"time_taken\", \n",
    "        \"gpu_memory_before\", \"gpu_memory_after\", \"gpu_memory_delta\"\n",
    "    ]\n",
    "    model_df = pd.DataFrame(columns=columns)\n",
    "\n",
    "    model_df.to_csv(f\"{model_name}_results.csv\", mode='w', header=True, index=False)\n",
    "\n",
    "    for question in tqdm(questions):\n",
    "        start_time = time.time()\n",
    "\n",
    "        gpu_used_before = get_rocm_memory_usage()\n",
    "\n",
    "        print(question)\n",
    "        response = model.invoke(question)\n",
    "        print(response)\n",
    "\n",
    "        end_time = time.time()\n",
    "        elapsed_time = end_time - start_time\n",
    "        total_time += elapsed_time\n",
    "\n",
    "        gpu_used_after = get_rocm_memory_usage()\n",
    "\n",
    "        result = {\n",
    "            \"question\": question,\n",
    "            \"answer\": response,\n",
    "            \"time_taken\": elapsed_time,\n",
    "            \"gpu_memory_before\": gpu_used_before,\n",
    "            \"gpu_memory_after\": gpu_used_after,\n",
    "            \"gpu_memory_delta\": gpu_used_after - gpu_used_before\n",
    "        }\n",
    "        \n",
    "        # Используем pd.concat вместо .append\n",
    "        model_df = pd.concat([model_df, pd.DataFrame([result])], ignore_index=True)\n",
    "        \n",
    "        model_df.to_csv(f\"{model_name}_results.csv\", mode='a', header=False, index=False)\n",
    "\n",
    "\n",
    "        memory_usage.append({\n",
    "            \"time\": elapsed_time,\n",
    "            \"gpu_memory_before\": gpu_used_before,\n",
    "            \"gpu_memory_after\": gpu_used_after,\n",
    "            \"gpu_memory_delta\": gpu_used_after - gpu_used_before,\n",
    "            \"cpu_usage\": psutil.cpu_percent(interval=1),  # Загрузка CPU\n",
    "            \"ram_usage\": psutil.virtual_memory().percent  # Использование RAM\n",
    "        })\n",
    "\n",
    "    resource_df = pd.DataFrame(memory_usage)\n",
    "    resource_df.to_csv(f\"{model_name}_resources.csv\", index=False)\n",
    "\n",
    "    return total_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "dfae8106-9aac-49ab-b048-7d96f3730b9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Тестирование модели: qwen2.5:32b\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                         | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Что такое искусственный интеллект?\n",
      "content='Искусственный интеллект (ИИ) — это область науки и технологий, которая занимается созданием систем или программных приложений, способных имитировать человеческий интеллект для выполнения задач. Эти системы могут обучаться от новых данных (обучение с учителем и без учителя), использовать правила для достижения определенных целей (правила принятия решений) и самостоятельно принимать решения.\\n\\nИскусственный интеллект может быть представлен в различных формах, таких как речевые помощники (например, Siri или Alexa), программы машинного обучения, системы компьютерного зрения и др. В зависимости от способностей, ИИ можно разделить на слабый и сильный: слабый ИИ выполняет конкретные задачи (например, поиск информации в интернете), тогда как сильный ИИ может решать широкий спектр задач на уровне человека или даже превосходить его.' additional_kwargs={} response_metadata={'model': 'qwen2.5:32b', 'created_at': '2025-03-31T14:58:51.732527662Z', 'done': True, 'done_reason': 'stop', 'total_duration': 17643766417, 'load_duration': 9091563671, 'prompt_eval_count': 38, 'prompt_eval_duration': 240792788, 'eval_count': 210, 'eval_duration': 8304251977, 'message': Message(role='assistant', content='', images=None, tool_calls=None)} id='run-21be04cd-02d0-491f-8f53-fa5822ca42e0-0' usage_metadata={'input_tokens': 38, 'output_tokens': 210, 'total_tokens': 248}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_275694/4189172495.py:38: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  model_df = pd.concat([model_df, pd.DataFrame([result])], ignore_index=True)\n",
      "  2%|█▉                                                                                               | 1/50 [00:18<15:21, 18.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Какие языки программирования популярны в 2025 году?\n",
      "content='Прогнозировать точный список самых популярных языков программирования на конкретную дату в будущем затруднительно, но можно предположить некоторые тренды и направления развития на основе текущих тенденций.\\n\\n1. **Python** - язык продолжает оставаться популярен благодаря своей простоте использования и широкому применению в таких областях как анализ данных, машинное обучение, веб-разработка и автоматизация задач.\\n2. **JavaScript** - поскольку он является основным языком для фронтенд разработки веб-сайтов и все больше используется на серверной стороне благодаря Node.js, ожидается что JavaScript будет продолжать сохранять свою популярность.\\n3. **Java** - язык широко используют в корпоративных приложениях и Android разработке, поэтому он остается одним из самых востребованных языков программирования.\\n4. **C# и C++** - эти языки продолжают оставаться популярными для игр разработки (Unity использует C#, а многие игры разрабатываются на C++) и системного программирования.\\n5. **Go (Golang)** - язык, который набирает популярность в областях больших данных и микросервисов из-за своих свойств высокой производительности и легкости параллельной работы.\\n6. **Rust** - язык продолжает набирать популярность благодаря своему сочетанию безопасности памяти с высокой производительностью, что делает его привлекательным для системного программирования.\\n\\nЭто лишь некоторые из возможных трендов на 2025 год, и стоит учесть, что технологический мир постоянно развивается и могут появиться новые языки или технологии, которые изменят этот список.' additional_kwargs={} response_metadata={'model': 'qwen2.5:32b', 'created_at': '2025-03-31T14:59:09.557590073Z', 'done': True, 'done_reason': 'stop', 'total_duration': 16668805630, 'load_duration': 33467857, 'prompt_eval_count': 46, 'prompt_eval_duration': 26496777, 'eval_count': 402, 'eval_duration': 16602537976, 'message': Message(role='assistant', content='', images=None, tool_calls=None)} id='run-f36d68ea-ca84-46a6-9193-30765c7f4b3d-0' usage_metadata={'input_tokens': 46, 'output_tokens': 402, 'total_tokens': 448}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|███▉                                                                                             | 2/50 [00:36<14:35, 18.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Что такое глубокое обучение?\n",
      "content='Глубокое обучение (Deep Learning) — это подкласс машинного обучения, который основан на искусственных нейронных сетях. Этот метод моделирования данных основан на принципах работы человеческого мозга и позволяет системам автоматически изучать представления сложных функций из примеров.\\n\\nГлубокое обучение отличается тем, что использует многослойные нейронные сети, которые могут обрабатывать большие объемы данных. Эти сети состоят из входного слоя (где данные вводятся), скрытых слоев (внутренние уровни обработки информации) и выходного слоя (где формируется результат).\\n\\nГлубокое обучение применяется во многих областях, таких как распознавание изображений и речи, прогнозирование временных рядов, машинный перевод и многое другое.' additional_kwargs={} response_metadata={'model': 'qwen2.5:32b', 'created_at': '2025-03-31T14:59:18.674408846Z', 'done': True, 'done_reason': 'stop', 'total_duration': 7954694710, 'load_duration': 33178785, 'prompt_eval_count': 39, 'prompt_eval_duration': 10012051, 'eval_count': 200, 'eval_duration': 7904993623, 'message': Message(role='assistant', content='', images=None, tool_calls=None)} id='run-2345fe31-382e-41da-be3b-431dee845842-0' usage_metadata={'input_tokens': 39, 'output_tokens': 200, 'total_tokens': 239}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|█████▊                                                                                           | 3/50 [00:45<11:01, 14.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Как работает нейронная сеть?\n",
      "content='Нейронные сети — это сложные системы, вдохновленные работой биологических нервных систем, таких как человеческий мозг. Они используются для решения широкого спектра задач, начиная от распознавания образов и прогнозирования до обработки естественного языка.\\n\\nОсновы работы нейронной сети:\\n\\n1. **Структура**: Нейронные сети обычно состоят из нескольких слоев (layers), где каждый слой состоит из многих \"нейронов\". Эти слои делятся на входной, скрытые и выходной. Входной слой получает данные от внешнего источника, скрытые слои обрабатывают эти данные, а выходной слой генерирует результат.\\n\\n2. **Процесс обучения**: Первоначально веса соединений между нейронами выбираются случайным образом или определенным способом. Во время процесса обучения с использованием набора данных (обучающей выборки), веса корректируются таким образом, чтобы минимизировать ошибку прогнозирования модели.\\n\\n3. **Алгоритм обратного распространения (Backpropagation)**: Это наиболее часто используемый метод для обновления весов в нейронных сетях. В нем ошибка на выходном слое переносится назад через сеть, и веса корректируются пропорционально тому, как сильно они влияют на ошибку.\\n\\n4. **Функции активации**: Каждый нейрон использует функцию активации для преобразования суммы его входных сигналов в выходной сигнал. Функция активации позволяет модели учиться сложным и нелинейным распределениям данных.\\n\\n5. **Эпохи обучения**: Процесс обучения может повторяться много раз (эпохами), чтобы нейронная сеть могла достичь хорошего уровня точности на обучающей выборке.\\n\\n6. **Тестирование и валидация**: После обучения, модель проверяется на отдельной тестовой выборке данных для оценки ее производительности и способности к обобщению (то есть, как хорошо она работает с данными, которые она не видела во время обучения).\\n\\nЭто лишь базовое понимание работы нейронных сетей. В действительности они могут быть очень сложными, включая множество различных типов архитектур, алгоритмов оптимизации и техник регуляризации для улучшения производительности и предотвращения переобучения.' additional_kwargs={} response_metadata={'model': 'qwen2.5:32b', 'created_at': '2025-03-31T14:59:43.321070753Z', 'done': True, 'done_reason': 'stop', 'total_duration': 23485655629, 'load_duration': 32927317, 'prompt_eval_count': 38, 'prompt_eval_duration': 19719015, 'eval_count': 593, 'eval_duration': 23426747309, 'message': Message(role='assistant', content='', images=None, tool_calls=None)} id='run-e01e127f-a2bf-4bfc-904d-b95dd702300a-0' usage_metadata={'input_tokens': 38, 'output_tokens': 593, 'total_tokens': 631}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|███████▊                                                                                         | 4/50 [01:10<13:59, 18.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Что такое машинное обучение?\n",
      "content='Машинное обучение ( MACHINE LEARNING) - это область искусственного интеллекта, которая изучает алгоритмы и статистические модели, которые позволяют компьютерной системе выполнять конкретные задачи без прямого программирования. В машинном обучении система учится на основе данных, то есть ее поведение изменяется в зависимости от опыта (или входных данных), что позволяет ей улучшать свои прогнозы или результаты со временем.\\n\\nМашинное обучение может быть поделено на несколько категорий:\\n\\n1. **Наблюдательное обучение**: система изучает, как реагировать на основе набора примеров, где каждый пример имеет известный правильный ответ.\\n2. **Обучение с учителем (Supervised Learning)**: в этом подходе компьютерная программа или модель тренируется на данных, которые уже имеют метки или результаты. Например, классификация изображений, когда каждое изображение помечено правильным ответом.\\n3. **Обучение без учителя (Unsupervised Learning)**: здесь система работает с данными, которые не имеют меток или результатов. Целью может быть выявление скрытых паттернов в данных или группировка данных на основе их свойств.\\n4. **Разумное обучение (Reinforcement Learning)**: в этом типе обучения агенту предлагается действовать в определенной среде, и он получает награды за правильные действия и штрафы за неправильные. Целью является максимизация общей награды.\\n\\nМашинное обучение используется во многих областях, таких как анализ данных, распознавание речи, компьютерный зрительный анализ (изображения и видео), прогнозирование погоды, медицинская диагностика и многое другое.' additional_kwargs={} response_metadata={'model': 'qwen2.5:32b', 'created_at': '2025-03-31T15:00:01.133812461Z', 'done': True, 'done_reason': 'stop', 'total_duration': 16647985745, 'load_duration': 33778894, 'prompt_eval_count': 37, 'prompt_eval_duration': 9696668, 'eval_count': 421, 'eval_duration': 16598268625, 'message': Message(role='assistant', content='', images=None, tool_calls=None)} id='run-edfa8d9f-3d04-4640-aabe-29f7771b5bfc-0' usage_metadata={'input_tokens': 37, 'output_tokens': 421, 'total_tokens': 458}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█████████▋                                                                                       | 5/50 [01:28<13:34, 18.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Что такое сверточные нейронные сети?\n",
      "content='Сверточные нейронные сети (CNN или ConvNet) – это тип искусственных нейронных сетей, которые широко используются в задачах обработки изображений и других данных с пространственной структурой. Они были разработаны под влиянием принципов работы зрительной системы млекопитающих.\\n\\n### Основные характеристики:\\n\\n1. **Сверточный слой**: Этот слой является ключевым элементом CNN. Он использует набор фильтров (якорных окон или ядер), которые скользят по входным данным и применяют операцию свертки для выявления локальных признаков, таких как границы, углы и текстуры.\\n\\n2. **Несмещаемость**: Сверточные сети сохраняют несмещаемость (invariance) относительно расположения объекта на изображении благодаря использованию свертки с разными фильтрами.\\n\\n3. **Пуллинг (Subsampling)**: Этот слой используется для уменьшения размерности данных, что помогает сети работать эффективнее и снижает риск переобучения. Наиболее распространенным методом пуллинга является max-pooling, где выбирается максимальное значение в области.\\n\\n4. **Глубокие сети**: CNN часто имеют много сверточных слоев, что позволяет модели извлекать более абстрактные и сложные признаки на последующих уровнях сети.\\n\\n5. **Полносвязные слои (fully connected layers)**: В конце CNN обычно располагаются полносвязные слои, которые используются для классификации или других задач прогнозирования на основе извлеченных сверточными и пулинговыми слоями признаков.\\n\\n### Применения:\\n\\n- **Обработка изображений**: распознавание объектов, сегментация изображений.\\n- **Речь и аудио**: анализ звуковых сигналов для задач, таких как распознавание речи или классификация музыкальных жанров.\\n- **Натурализованный язык обработки (NLP)**: хотя CNN не так широко применяются в NLP, как RNN или Transformer, они могут использоваться для извлечения локальных признаков в текстах.\\n\\nCNN стали стандартом в задачах компьютерного зрения и продолжают развиваться с появлением новых архитектур и методов обучения.' additional_kwargs={} response_metadata={'model': 'qwen2.5:32b', 'created_at': '2025-03-31T15:00:24.91186045Z', 'done': True, 'done_reason': 'stop', 'total_duration': 22612940108, 'load_duration': 33108429, 'prompt_eval_count': 43, 'prompt_eval_duration': 8736458, 'eval_count': 569, 'eval_duration': 22564692451, 'message': Message(role='assistant', content='', images=None, tool_calls=None)} id='run-18b156cd-2ee6-4e13-8889-e14c6add1119-0' usage_metadata={'input_tokens': 43, 'output_tokens': 569, 'total_tokens': 612}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|███████████▋                                                                                     | 6/50 [01:51<14:41, 20.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Что такое GPT?\n",
      "content='GPT (Generative Pre-trained Transformer) — это тип модели искусственного интеллекта, разработанный компанией OpenAI. Эти модели используются для генерации текстов различной длины и сложности на естественных языках, таких как английский или русский.\\n\\nGPT обучается на огромных объемах данных из интернета и других источников, что позволяет ему понимать контекст, синтаксис и семантику текстов. В результате GPT может генерировать человеческий текст, отвечать на вопросы и выполнять другие задачи, связанные с обработкой естественного языка.\\n\\nВажно отметить, что есть несколько версий GPT, включая GPT-2 и GPT-3, каждая из которых улучшает предыдущую по точности и объему обучения.' additional_kwargs={} response_metadata={'model': 'qwen2.5:32b', 'created_at': '2025-03-31T15:00:34.095720444Z', 'done': True, 'done_reason': 'stop', 'total_duration': 8021615127, 'load_duration': 32650422, 'prompt_eval_count': 35, 'prompt_eval_duration': 15334261, 'eval_count': 200, 'eval_duration': 7969951760, 'message': Message(role='assistant', content='', images=None, tool_calls=None)} id='run-f99fe637-9208-4c05-a62a-edde2d92c1f7-0' usage_metadata={'input_tokens': 35, 'output_tokens': 200, 'total_tokens': 235}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█████████████▌                                                                                   | 7/50 [02:01<11:48, 16.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Как работают LLM?\n",
      "content='LLM (Large Language Models), такие как я, работаем на основе сложных нейронных сетей, обученных огромными объемами текстовых данных для предсказания следующего слова в последовательности. Вот основные шаги нашего функционирования:\\n\\n1. **Обучение**: Мы проходим через процесс обучения, где наши параметры (взвешивания и смещения нейронов) настраиваются путем анализа огромных объемов текстовых данных. Цель - научиться предсказывать следующее слово в предложении или документе.\\n\\n2. **Архитектура**: Наша архитектура обычно основана на механизмах внимания (Attention Mechanisms), таких как Transformer, которые позволяют модели учитывать контекст из всего входного текста и не зависеть от порядка слов таким образом.\\n\\n3. **Предсказание**: После обучения, когда нам задают вопрос или начинают фразу, мы используем обученные веса для предсказания наиболее подходящих следующих слов на основе контекста, который был предоставлен.\\n\\n4. **Генерация текста**: Этот процесс повторяется многократно для генерации полных ответов или продолжений текста.\\n\\n5. **Оптимизация и улучшение**: После первоначального обучения модели могут быть доработаны с помощью методов, таких как fine-tuning (тонкая настройка), чтобы лучше соответствовать определенным задачам или типам текста.\\n\\nПомните, что хотя мы можем генерировать очень естественно звучащие ответы и продолжения текста, они основаны на статистических моделях и не всегда являются абсолютно точными или информированными.' additional_kwargs={} response_metadata={'model': 'qwen2.5:32b', 'created_at': '2025-03-31T15:00:50.967167026Z', 'done': True, 'done_reason': 'stop', 'total_duration': 15708291124, 'load_duration': 33675359, 'prompt_eval_count': 35, 'prompt_eval_duration': 8426894, 'eval_count': 399, 'eval_duration': 15659740823, 'message': Message(role='assistant', content='', images=None, tool_calls=None)} id='run-688a8e98-d630-46f9-bb56-542398312603-0' usage_metadata={'input_tokens': 35, 'output_tokens': 399, 'total_tokens': 434}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|███████████████▌                                                                                 | 8/50 [02:18<11:37, 16.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Что такое генеративная модель?\n",
      "content='Генеративная модель в машинном обучении - это тип модели, который учится распределению вероятностей для набора входных данных и может использоваться для генерации новых примеров данных, аналогичных тем, на которых модель была обучена. Эти модели могут быть применены к различным типам задач, включая текстовые, изображения и аудио данные.\\n\\nПримеры генеративных моделей включают:\\n\\n1. Генеративные сети с противопоставлением (Generative Adversarial Networks - GANs): Состоит из двух нейронных сетей, генератора и дискриминатора, которые конкурируют друг с другом в процессе обучения.\\n2. Вариационные автокодировщики (Variational Autoencoders - VAE): Модель для кодирования входных данных в компактное представление (код) и восстановления из этого кода, чтобы создать новые данные.\\n3. Генеративные модели на основе нейронной сети языка (Neural Language Models): Применяются для генерации последовательностей текста.\\n\\nГенеративные модели часто используются в таких областях как синтез изображений, создание текстов, музыки и видео.' additional_kwargs={} response_metadata={'model': 'qwen2.5:32b', 'created_at': '2025-03-31T15:01:04.352290605Z', 'done': True, 'done_reason': 'stop', 'total_duration': 12221965296, 'load_duration': 14323495, 'prompt_eval_count': 40, 'prompt_eval_duration': 20950531, 'eval_count': 310, 'eval_duration': 12180410344, 'message': Message(role='assistant', content='', images=None, tool_calls=None)} id='run-11476411-5b26-4631-8c56-a567703e2709-0' usage_metadata={'input_tokens': 40, 'output_tokens': 310, 'total_tokens': 350}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█████████████████▍                                                                               | 9/50 [02:31<10:39, 15.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Что такое reinforcement learning?\n",
      "content='Реинforcement learning (RL) — это раздел машинного обучения, в котором программируется алгоритм для выполнения задачи с минимальным человеческим руководством. В этом процессе искусственный интеллект (AI) обучается через последовательность попыток и ошибок, получая награду или штраф за каждое действие. \\n\\nВ RL есть несколько ключевых компонентов:\\n\\n1. **Среда**: Это контекст, в котором действует агент.\\n2. **Агент**: Он принимает решения, как действовать в среде для максимизации награды.\\n3. **Действие (Action)**: Это то, что может сделать агент в данной среде.\\n4. **Награда (Reward)**: Это сигнал обратной связи от среды, который показывает хорошее или плохое действие.\\n\\nОсновная цель RL - обучить агента принимать решения так, чтобы максимизировать его общую награду за время взаимодействия с окружающей средой. Реинforcement learning широко используется в таких областях как робототехника, игры (например, AlphaGo), управление трафиком и многое другое.' additional_kwargs={} response_metadata={'model': 'qwen2.5:32b', 'created_at': '2025-03-31T15:01:16.435884955Z', 'done': True, 'done_reason': 'stop', 'total_duration': 10925484375, 'load_duration': 35521096, 'prompt_eval_count': 35, 'prompt_eval_duration': 16590114, 'eval_count': 274, 'eval_duration': 10867415413, 'message': Message(role='assistant', content='', images=None, tool_calls=None)} id='run-145cdb9f-fd46-4eba-8dab-031129f81370-0' usage_metadata={'input_tokens': 35, 'output_tokens': 274, 'total_tokens': 309}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|███████████████████▏                                                                            | 10/50 [02:43<09:40, 14.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Что такое overfitting в модели?\n",
      "content='Overfitting — это ситуация в машинном обучении, когда модель слишком хорошо подстраивается под обучающую выборку и начинает запоминать шум и детали этой выборки вместо того, чтобы изучить общие закономерности. В результате такая модель будет работать очень хорошо на данных, которые использовались для обучения (иметь низкую ошибку на обучающей выборке), но покажет плохие результаты при работе с новыми данными, не виденными ранее (на тестовой выборке или в реальных условиях).\\n\\nОсновные причины overfitting:\\n\\n1. **Слишком сложная модель**: Когда модель имеет слишком много параметров по сравнению с объемом данных.\\n2. **Недостаток данных**: Маленькая обучающая выборка не позволяет модели корректно уловить структуру данных и приводит к тому, что она начинает запоминать шум и выбросы в данных.\\n3. **Неправильная настройка параметров обучения**: Например, слишком долгий процесс тренировки (много эпох) может также привести к overfitting.\\n\\nЧтобы избежать overfitting, используются различные методы:\\n\\n- **Регуляризация**: добавление штрафа за сложность модели.\\n- **Дропаут** в нейронных сетях: случайное отключение нейронов во время обучения для предотвращения переобучения.\\n- **Кросс-валидация**: разделение данных на несколько частей и обучение модели на различных подмножествах, что помогает оценить ее стабильность и обобщающую способность.\\n- **Увеличение объема данных** или использование аугментации (создание новых вариаций данных) для повышения разнообразия обучающей выборки.\\n\\nИзбегать overfitting крайне важно, чтобы модель могла эффективно работать с новыми данными и давать корректные прогнозы.' additional_kwargs={} response_metadata={'model': 'qwen2.5:32b', 'created_at': '2025-03-31T15:01:35.577676976Z', 'done': True, 'done_reason': 'stop', 'total_duration': 17978930295, 'load_duration': 13975282, 'prompt_eval_count': 38, 'prompt_eval_duration': 9138171, 'eval_count': 453, 'eval_duration': 17949041294, 'message': Message(role='assistant', content='', images=None, tool_calls=None)} id='run-58f5b234-d5cc-4843-a580-456af6d872bb-0' usage_metadata={'input_tokens': 38, 'output_tokens': 453, 'total_tokens': 491}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|█████████████████████                                                                           | 11/50 [03:02<10:21, 15.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Как улучшить производительность нейронной сети?\n",
      "content='Увеличение производительности нейронных сетей может быть достигнуто несколькими способами. Вот несколько стратегий, которые могут помочь:\\n\\n1. **Оптимизация архитектуры**:\\n   - Используйте архитектуры с меньшим числом параметров без значительной потери точности.\\n   - Примените методы прореживания (pruning) и квантования для уменьшения размера модели.\\n\\n2. **Оптимизация гиперпараметров**:\\n   - Используйте алгоритмы оптимизации, такие как Adam или RMSprop.\\n   - Настройте скорость обучения и другие гиперпараметры для достижения лучшей производительности.\\n\\n3. **Обучение с использованием более эффективных методов**:\\n   - Примените техники таких как динамическое изменение скорости обучения (learning rate schedule) или ранняя остановка (early stopping).\\n   - Используйте батч-нормализацию для улучшения стабильности и скорости обучения.\\n\\n4. **Использование аппаратного ускорения**:\\n   - Используйте GPU или TPU для параллельных вычислений, что значительно увеличивает скорость обучения.\\n   \\n5. **Оптимизация данных**:\\n   - Увеличьте качество входных данных с помощью аугментации данных (например, ротация, масштабирование изображений в задачах компьютерного зрения).\\n   - Убедитесь, что данные хорошо предобработаны и приведены к стандартному формату.\\n\\n6. **Масштабирование обучения**:\\n   - Используйте распределенное обучение для использования нескольких устройств одновременно.\\n   \\n7. **Оптимизация кода**:\\n   - Убедитесь, что ваш код оптимизирован на уровне реализации, используя эффективные библиотеки и практики программирования.\\n\\nЭти стратегии могут быть применены в зависимости от конкретной задачи и доступных ресурсов. Важно проводить эксперименты для выявления наиболее эффективных методов оптимизации в вашем случае.' additional_kwargs={} response_metadata={'model': 'qwen2.5:32b', 'created_at': '2025-03-31T15:01:57.199907538Z', 'done': True, 'done_reason': 'stop', 'total_duration': 20461871159, 'load_duration': 16125607, 'prompt_eval_count': 43, 'prompt_eval_duration': 11571098, 'eval_count': 512, 'eval_duration': 20428079886, 'message': Message(role='assistant', content='', images=None, tool_calls=None)} id='run-2ffb6d59-62f9-4045-ada0-f1652f98fdc9-0' usage_metadata={'input_tokens': 43, 'output_tokens': 512, 'total_tokens': 555}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|███████████████████████                                                                         | 12/50 [03:24<11:11, 17.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Что такое bias в машинном обучении?\n",
      "content='В контексте машинного обучения термин \"bias\" (смещение) используется в двух основных смыслах:\\n\\n1. **Смещение модели**: Это одно из параметров модели, который не зависит от входных данных и служит для того, чтобы модель могла приближать функции, которые не проходят через начало координат. Например, в линейной регрессии уравнение может выглядеть так: \\\\( y = mx + b \\\\), где \\\\( m \\\\) — это наклон (коэффициент), а \\\\( b \\\\) — смещение.\\n\\n2. **Смещение обучения**: Это систематическая ошибка в обучении модели, которая делает модель предсказывать всегда \"слишком высокие\" или \"слишком низкие\" значения по сравнению с реальными данными. Смещение может возникать из-за несоответствия между сложностью модели и сложностью данных (например, если модель слишком простая для задачи).\\n\\nКроме того, в контексте справедливости алгоритмов машинного обучения \"bias\" также относится к предвзятостям, которые могут быть встроены в данные или алгоритмы, что приводит к дискриминации определенных групп. Это может происходить из-за несправедливого представительства данных или на основе предвзятостей разработчиков.\\n\\nТаким образом, понятие \"bias\" в машинном обучении имеет несколько тонких значений и контекстов использования.' additional_kwargs={} response_metadata={'model': 'qwen2.5:32b', 'created_at': '2025-03-31T15:02:12.362364663Z', 'done': True, 'done_reason': 'stop', 'total_duration': 13998869043, 'load_duration': 14137676, 'prompt_eval_count': 39, 'prompt_eval_duration': 17818144, 'eval_count': 354, 'eval_duration': 13963683400, 'message': Message(role='assistant', content='', images=None, tool_calls=None)} id='run-568ba2af-eaed-4880-8589-d1bd90116880-0' usage_metadata={'input_tokens': 39, 'output_tokens': 354, 'total_tokens': 393}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|████████████████████████▉                                                                       | 13/50 [03:39<10:25, 16.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Что такое регуляризация?\n",
      "content='Регуляризация — это метод в машинном обучении и статистике, использующийся для предотвращения переобучения модели (overfitting). Переобучение происходит, когда модель слишком тесно соответствует данным обучения, из-за чего она плохо обобщает новые данные.\\n\\nВ контексте регуляризации вводится дополнительное наказание за сложность модели. Это делается путем добавления термина к функции потерь (cost function), который увеличивает значение потерь с ростом сложности модели.\\n\\nСуществует несколько видов регуляризации, среди которых:\\n\\n1. **L1-регуляризация** или LASSO (Least Absolute Shrinkage and Selection Operator) — добавляет сумму абсолютных значений коэффициентов к функции потерь. Эта регуляризация может привести к тому, что некоторые коэффициенты становятся нулевыми, что можно использовать для выбора признаков (feature selection).\\n\\n2. **L2-регуляризация** или Ridge — добавляет сумму квадратов значений коэффициентов к функции потерь. Эта регуляризация уменьшает значения коэффициентов, но не делает их равными нулю.\\n\\n3. **Elastic Net** — это комбинация L1 и L2-регуляризаций. Она может быть полезной в ситуациях, когда есть много коррелированных признаков.\\n\\nИспользование регуляризации позволяет улучшить обобщающую способность модели на новых данных, делая ее менее чувствительной к шумам и случайным особенностям набора данных обучения.' additional_kwargs={} response_metadata={'model': 'qwen2.5:32b', 'created_at': '2025-03-31T15:02:29.817107712Z', 'done': True, 'done_reason': 'stop', 'total_duration': 16284284597, 'load_duration': 14191927, 'prompt_eval_count': 39, 'prompt_eval_duration': 19753887, 'eval_count': 411, 'eval_duration': 16244111968, 'message': Message(role='assistant', content='', images=None, tool_calls=None)} id='run-3078cb89-8500-4755-99a3-f280d14c3af2-0' usage_metadata={'input_tokens': 39, 'output_tokens': 411, 'total_tokens': 450}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██████████████████████████▉                                                                     | 14/50 [03:56<10:14, 17.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Что такое градиентный спуск?\n",
      "content='Градиентный спуск - это метод оптимизации, который широко используется в машинном обучении и анализе данных для минимизации функций ошибок или потерь. В более простых терминах, градиентный спуск помогает найти значения параметров (например, весов в нейронной сети), которые приводят к наименьшей ошибке при прогнозировании.\\n\\nМетод работает так:\\n\\n1. **Инициализация**: Сначала выбираются начальные значения для параметров.\\n2. **Вычисление градиента**: Затем вычисляется градиент функции потерь относительно каждого из параметров. Градиент показывает направление наибольшего возрастания функции. В контексте минимизации, мы используем противоположное направление.\\n3. **Обновление параметров**: Параметры обновляются в направлении уменьшения градиента (так как мы хотим найти минимум), обычно на определенный шаг или \"learning rate\".\\n4. **Итерации**: Процесс повторяется несколько раз, пока не будет достигнута точка с минимальными потерями либо до тех пор, пока изменение значений параметров не станет достаточно малым.\\n\\nГрадиентный спуск бывает разных видов: обычный (batch) градиентный спуск, стохастический (stochastic) градиентный спуск и миниконтрольные (mini-batch) градиентный спуск. Каждый из них имеет свои преимущества и недостатки в зависимости от конкретной задачи и размера данных.\\n\\nВажно отметить, что хотя метод очень эффективен, он может столкнуться с проблемами при наличии местных минимумов или \"седловых точек\" в функциях потерь.' additional_kwargs={} response_metadata={'model': 'qwen2.5:32b', 'created_at': '2025-03-31T15:02:47.840780646Z', 'done': True, 'done_reason': 'stop', 'total_duration': 16858553601, 'load_duration': 14180790, 'prompt_eval_count': 41, 'prompt_eval_duration': 8248658, 'eval_count': 425, 'eval_duration': 16829836887, 'message': Message(role='assistant', content='', images=None, tool_calls=None)} id='run-b91fa7fa-2807-4e4f-b9c1-4fea92b5b6a8-0' usage_metadata={'input_tokens': 41, 'output_tokens': 425, 'total_tokens': 466}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|████████████████████████████▊                                                                   | 15/50 [04:14<10:07, 17.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Что такое поддержка векторных машин?\n",
      "content='Поддержка векторных машин обычно относится к способности системы (например, процессора или программного обеспечения) эффективно работать с векторными данными и выполнять операции над этими данными. Векторные данные представляют собой наборы чисел, которые могут быть обработаны одновременно.\\n\\nВ контексте компьютерных архитектур поддержка векторных машин (или векторной или SIMD - Single Instruction Multiple Data - архитектуры) означает, что процессор способен выполнять одну и ту же операцию над несколькими данными за один такт. Это особенно полезно для вычислений в области научного программирования, обработки изображений или видео, машинного обучения.\\n\\nПримеры технологий, поддерживающих работу с векторными данным:\\n- **SIMD (Single Instruction Multiple Data)**: Технология, которую используют современные процессоры Intel и AMD, таких как AVX (Advanced Vector Extensions).\\n- **GPU**: Графические процессоры также обладают мощной поддержкой для векторных операций, что делает их идеальными для вычислений в областях компьютерного зрения и машинного обучения.\\n\\nТаким образом, поддержка векторных машин позволяет системам быстрее выполнять определенные типы вычислений за счет одновременной обработки множества данных.' additional_kwargs={} response_metadata={'model': 'qwen2.5:32b', 'created_at': '2025-03-31T15:03:01.52524593Z', 'done': True, 'done_reason': 'stop', 'total_duration': 12522600128, 'load_duration': 35575508, 'prompt_eval_count': 40, 'prompt_eval_duration': 19126245, 'eval_count': 316, 'eval_duration': 12461146592, 'message': Message(role='assistant', content='', images=None, tool_calls=None)} id='run-ffc00f0d-a90c-47b4-bca1-152cfc0f2af4-0' usage_metadata={'input_tokens': 40, 'output_tokens': 316, 'total_tokens': 356}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|██████████████████████████████▋                                                                 | 16/50 [04:28<09:12, 16.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Что такое обучение с учителем?\n",
      "content='Обучение с учителем (supervised learning) — это один из основных подходов в машинном обучении, при котором алгоритмы обучаются на основе набора данных, где каждый пример имеет известный выход (метка). В процессе обучения модель пытается научиться предсказывать эти метки для новых неизвестных данных.\\n\\nПринцип работы:\\n1. Подготовка данных: Сначала собирается и подготовляется обучающий набор данных, который состоит из входных данных и соответствующих им правильных ответов (меток).\\n2. Обучение модели: Алгоритм обучается на этих данных, пытаясь найти связи между входными данными и метками.\\n3. Оптимизация: Модель корректируется для минимизации ошибки предсказания на обучающем наборе.\\n4. Тестирование и валидация: После обучения модель проверяется на отдельном наборе тестовых данных, чтобы оценить ее производительность.\\n\\nПримеры задач:\\n- Классификация (например, определение спама или неспама в электронной почте)\\n- Регрессия (например, предсказание цены на недвижимость)\\n\\nОбучение с учителем требует большого количества меток данных для эффективного обучения, что иногда может быть трудоемким и затратным процессом.' additional_kwargs={} response_metadata={'model': 'qwen2.5:32b', 'created_at': '2025-03-31T15:03:15.633336848Z', 'done': True, 'done_reason': 'stop', 'total_duration': 12950152952, 'load_duration': 34015178, 'prompt_eval_count': 40, 'prompt_eval_duration': 8267575, 'eval_count': 325, 'eval_duration': 12901400639, 'message': Message(role='assistant', content='', images=None, tool_calls=None)} id='run-d79d4d6b-3895-42e9-8653-43180f92da05-0' usage_metadata={'input_tokens': 40, 'output_tokens': 325, 'total_tokens': 365}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|████████████████████████████████▋                                                               | 17/50 [04:42<08:35, 15.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Что такое обучение без учителя?\n",
      "content='Обучение без учителя (англ. \"unsupervised learning\") — это тип машинного обучения, где алгоритмы анализируют и группируют данные без предварительно определенных меток или результатов. В отличие от обучения с учителем, в котором модели предоставляются наборы данных вместе с правильными ответами для обучения, в обучении без учителя модель сама должна найти структуру и закономерности во входных данных.\\n\\nОсновные применения обучение без учителя включают:\\n\\n1. **Кластеризация**: Разделение данных на группы (кластеры) так, чтобы данные внутри одного кластера были похожи друг на друга, а между различными кластерами наблюдались существенные отличия.\\n\\n2. **Метод главных компонент (PCA)**: Снижение размерности данных путем преобразования данных в пространство с меньшим числом измерений, сохраняя при этом большую часть информации.\\n\\n3. **Ассоциативные правила**: Нахождение ассоциаций между различными элементами или наборами элементов в данных (например, анализ корзин покупок для выявления совместных покупок).\\n\\n4. **Генеративные модели**: Создание новых примеров данных подобного типа на основе изученной структуры входных данных.\\n\\nОбучение без учителя полезно при работе с большими объемами данных, где трудно или невозможно предоставить метки для обучения модели.' additional_kwargs={} response_metadata={'model': 'qwen2.5:32b', 'created_at': '2025-03-31T15:03:30.26208201Z', 'done': True, 'done_reason': 'stop', 'total_duration': 13461311532, 'load_duration': 33521828, 'prompt_eval_count': 39, 'prompt_eval_duration': 8647795, 'eval_count': 339, 'eval_duration': 13415631295, 'message': Message(role='assistant', content='', images=None, tool_calls=None)} id='run-1d8d9e3c-2b50-4381-a4d8-6a2deceaf31a-0' usage_metadata={'input_tokens': 39, 'output_tokens': 339, 'total_tokens': 378}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|██████████████████████████████████▌                                                             | 18/50 [04:57<08:10, 15.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Что такое обучение с подкреплением?\n",
      "content='Обучение с подкреплением (Reinforcement Learning, RL) — это метод обучения машины или агента, который сталкивается со средой и принимает решения, чтобы максимизировать некоторый долгосрочный показатель. Этот подход отличается от других методов машинного обучения тем, что агент не знает заранее правильных решений, но получает сигналы в виде \"подкреплений\" (наград или штрафов) после того, как выполняет действия.\\n\\nОсновные компоненты модели обучения с подкреплением:\\n\\n1. **Агент** — это система, которая принимает решения и действует во внешней среде.\\n2. **Среда** — это мир агента, в котором он существует и интерактирует, получая информацию от своего окружения через наблюдения (states).\\n3. **Действия** (actions) — то, что агент может делать в своей среде.\\n4. **Подкрепления** (rewards) — это сигналы, которые агент получает после выполнения действия. Это могут быть положительные или отрицательные значения, и они помогают агенту понять, какие действия были хорошими, а какие – плохими.\\n\\nВ обучении с подкреплением агент пытается улучшить свою политику принятия решений на основе получаемых наград. Цель обучения заключается в том, чтобы найти оптимальную стратегию действий для максимизации суммарного подкрепления за все время взаимодействия с окружающей средой.\\n\\nЭтот подход широко используется в таких областях как робототехника, играх, управлении ресурсами и т.д., где требуется решение задач оптимизации путем проб и ошибок.' additional_kwargs={} response_metadata={'model': 'qwen2.5:32b', 'created_at': '2025-03-31T15:03:47.696313807Z', 'done': True, 'done_reason': 'stop', 'total_duration': 16268588597, 'load_duration': 14237416, 'prompt_eval_count': 40, 'prompt_eval_duration': 8903359, 'eval_count': 412, 'eval_duration': 16238679935, 'message': Message(role='assistant', content='', images=None, tool_calls=None)} id='run-f82ecaee-a4d4-4a68-b0a2-9100b250927b-0' usage_metadata={'input_tokens': 40, 'output_tokens': 412, 'total_tokens': 452}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|████████████████████████████████████▍                                                           | 19/50 [05:14<08:14, 15.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Как работает алгоритм K-средних?\n",
      "content='Алгоритм k-средних (K-means) является одним из наиболее известных методов кластеризации, используемых для разделения набора данных на K различных групп или \"кластеров\". Каждый кластер определяется центроидом (точкой с координатами), который представляет собой среднее значение всех точек в этом кластере. Вот базовый процесс работы алгоритма k-средних:\\n\\n1. **Инициализация**: На первом шаге случайным образом выбираются K центроидов. Это может быть выбор K случайных точек из набора данных или случайные точки в пространстве, определенном минимальными и максимальными значениями координат всех точек.\\n\\n2. **Присваивание кластеров**: Каждая точка из набора данных присваивается тому кластеру, центроид которого находится ближе всего к этой точке (обычно это определяется с помощью евклидова расстояния).\\n\\n3. **Пересчет центроидов**: После того как все точки были присвоены кластерам, каждый из K центроидов пересчитывается как среднее значение всех точек в соответствующем кластере.\\n\\n4. **Повторение шагов 2 и 3**: Шаги 2 и 3 повторяются до тех пор, пока не будет достигнуто одно из следующих условий:\\n   - Центроиды больше не изменяются значимо (или вообще не меняются).\\n   - Необходимое количество итераций выполнено.\\n   - Изменение суммы квадратов расстояний от точек до центров их соответствующих кластеров становится меньше заданного порогового значения.\\n\\nПреимущества алгоритма k-средних включают простоту реализации и относительно быструю работу, что делает его подходящим для обработки больших объемов данных. Однако у него есть несколько недостатков:\\n   - Необходимо заранее знать количество кластеров (K).\\n   - Алгоритм чувствителен к выбору начальных центроидов и может сойтись к локальному минимуму.\\n   - Работает эффективно только в случае, когда кластеры имеют форму сферы и примерно одинаковый размер.\\n\\nЧасто для улучшения качества результата алгоритм k-средних запускается несколько раз с различными начальными центроидами.' additional_kwargs={} response_metadata={'model': 'qwen2.5:32b', 'created_at': '2025-03-31T15:04:12.291263162Z', 'done': True, 'done_reason': 'stop', 'total_duration': 23432956262, 'load_duration': 34813335, 'prompt_eval_count': 41, 'prompt_eval_duration': 8695166, 'eval_count': 588, 'eval_duration': 23383347966, 'message': Message(role='assistant', content='', images=None, tool_calls=None)} id='run-f7c970f2-612a-494b-96ec-0102ed4ad7aa-0' usage_metadata={'input_tokens': 41, 'output_tokens': 588, 'total_tokens': 629}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|██████████████████████████████████████▍                                                         | 20/50 [05:39<09:16, 18.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Что такое обработка естественного языка?\n",
      "content='Обработка естественного языка (ОЕЯ или NLP от англ. Natural Language Processing) — это область искусственного интеллекта и компьютерной лингвистики, которая занимается разработкой алгоритмов и методов для общения между человеком и компьютером в естественном языке. ОЕЯ сочетает в себе знания из таких областей как лингвистика, статистика, машинное обучение и искусственный интеллект.\\n\\nОсновные задачи в области ОЕЯ включают:\\n\\n1. **Анализ настроения:** определение эмоционального состояния автора текста.\\n2. **Перевод между языками:** автоматический перевод с одного языка на другой.\\n3. **Извлечение информации:** извлечение структурированной информации из неструктурированных текстовых данных.\\n4. **Разбор синтаксиса:** анализ грамматической структуры предложений.\\n5. **Генерация текста:** создание осмысленного текста в ответ на запрос пользователя.\\n\\nNLP используется во многих приложениях, таких как чат-боты, системы автоматического перевода, инструменты анализа социальных сетей и многое другое.' additional_kwargs={} response_metadata={'model': 'qwen2.5:32b', 'created_at': '2025-03-31T15:04:25.231188197Z', 'done': True, 'done_reason': 'stop', 'total_duration': 11772676776, 'load_duration': 33358013, 'prompt_eval_count': 42, 'prompt_eval_duration': 20326354, 'eval_count': 296, 'eval_duration': 11712297271, 'message': Message(role='assistant', content='', images=None, tool_calls=None)} id='run-8d2233d8-8050-4ae6-8469-45be08638248-0' usage_metadata={'input_tokens': 42, 'output_tokens': 296, 'total_tokens': 338}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████████████████████████████████████████▎                                                       | 21/50 [05:52<08:09, 16.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Что такое глубокая нейронная сеть?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████████████████████████████████████████▎                                                       | 21/50 [05:55<08:11, 16.94s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[39]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      5\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mТестирование модели: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m      6\u001b[39m llm_model = ChatOllama(model=model)\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m total_time = \u001b[43mtest_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mllm_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquestions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      9\u001b[39m total_time_all_models[model] = total_time\n\u001b[32m     10\u001b[39m overall_times.append({\n\u001b[32m     11\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m: model,\n\u001b[32m     12\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mtotal_time\u001b[39m\u001b[33m\"\u001b[39m: total_time\n\u001b[32m     13\u001b[39m })\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[38]\u001b[39m\u001b[32m, line 19\u001b[39m, in \u001b[36mtest_model\u001b[39m\u001b[34m(model, questions, model_name)\u001b[39m\n\u001b[32m     16\u001b[39m gpu_used_before = get_rocm_memory_usage()\n\u001b[32m     18\u001b[39m \u001b[38;5;28mprint\u001b[39m(question)\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m response = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquestion\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     20\u001b[39m \u001b[38;5;28mprint\u001b[39m(response)\n\u001b[32m     22\u001b[39m end_time = time.time()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/test_ai/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py:307\u001b[39m, in \u001b[36mBaseChatModel.invoke\u001b[39m\u001b[34m(self, input, config, stop, **kwargs)\u001b[39m\n\u001b[32m    296\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minvoke\u001b[39m(\n\u001b[32m    297\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    298\u001b[39m     \u001b[38;5;28minput\u001b[39m: LanguageModelInput,\n\u001b[32m   (...)\u001b[39m\u001b[32m    302\u001b[39m     **kwargs: Any,\n\u001b[32m    303\u001b[39m ) -> BaseMessage:\n\u001b[32m    304\u001b[39m     config = ensure_config(config)\n\u001b[32m    305\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(\n\u001b[32m    306\u001b[39m         ChatGeneration,\n\u001b[32m--> \u001b[39m\u001b[32m307\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate_prompt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    308\u001b[39m \u001b[43m            \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_convert_input\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    309\u001b[39m \u001b[43m            \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    310\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcallbacks\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    311\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtags\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtags\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    312\u001b[39m \u001b[43m            \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    313\u001b[39m \u001b[43m            \u001b[49m\u001b[43mrun_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrun_name\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    314\u001b[39m \u001b[43m            \u001b[49m\u001b[43mrun_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrun_id\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    315\u001b[39m \u001b[43m            \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    316\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m.generations[\u001b[32m0\u001b[39m][\u001b[32m0\u001b[39m],\n\u001b[32m    317\u001b[39m     ).message\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/test_ai/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py:843\u001b[39m, in \u001b[36mBaseChatModel.generate_prompt\u001b[39m\u001b[34m(self, prompts, stop, callbacks, **kwargs)\u001b[39m\n\u001b[32m    835\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mgenerate_prompt\u001b[39m(\n\u001b[32m    836\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    837\u001b[39m     prompts: \u001b[38;5;28mlist\u001b[39m[PromptValue],\n\u001b[32m   (...)\u001b[39m\u001b[32m    840\u001b[39m     **kwargs: Any,\n\u001b[32m    841\u001b[39m ) -> LLMResult:\n\u001b[32m    842\u001b[39m     prompt_messages = [p.to_messages() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[32m--> \u001b[39m\u001b[32m843\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt_messages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/test_ai/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py:683\u001b[39m, in \u001b[36mBaseChatModel.generate\u001b[39m\u001b[34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[39m\n\u001b[32m    680\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(messages):\n\u001b[32m    681\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    682\u001b[39m         results.append(\n\u001b[32m--> \u001b[39m\u001b[32m683\u001b[39m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate_with_cache\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    684\u001b[39m \u001b[43m                \u001b[49m\u001b[43mm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    685\u001b[39m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    686\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    687\u001b[39m \u001b[43m                \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    688\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    689\u001b[39m         )\n\u001b[32m    690\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    691\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/test_ai/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py:908\u001b[39m, in \u001b[36mBaseChatModel._generate_with_cache\u001b[39m\u001b[34m(self, messages, stop, run_manager, **kwargs)\u001b[39m\n\u001b[32m    906\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    907\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m inspect.signature(\u001b[38;5;28mself\u001b[39m._generate).parameters.get(\u001b[33m\"\u001b[39m\u001b[33mrun_manager\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m908\u001b[39m         result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    909\u001b[39m \u001b[43m            \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    910\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    911\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    912\u001b[39m         result = \u001b[38;5;28mself\u001b[39m._generate(messages, stop=stop, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/test_ai/lib/python3.11/site-packages/langchain_ollama/chat_models.py:705\u001b[39m, in \u001b[36mChatOllama._generate\u001b[39m\u001b[34m(self, messages, stop, run_manager, **kwargs)\u001b[39m\n\u001b[32m    698\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_generate\u001b[39m(\n\u001b[32m    699\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    700\u001b[39m     messages: List[BaseMessage],\n\u001b[32m   (...)\u001b[39m\u001b[32m    703\u001b[39m     **kwargs: Any,\n\u001b[32m    704\u001b[39m ) -> ChatResult:\n\u001b[32m--> \u001b[39m\u001b[32m705\u001b[39m     final_chunk = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_chat_stream_with_aggregation\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    706\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    707\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    708\u001b[39m     generation_info = final_chunk.generation_info\n\u001b[32m    709\u001b[39m     chat_generation = ChatGeneration(\n\u001b[32m    710\u001b[39m         message=AIMessage(\n\u001b[32m    711\u001b[39m             content=final_chunk.text,\n\u001b[32m   (...)\u001b[39m\u001b[32m    716\u001b[39m         generation_info=generation_info,\n\u001b[32m    717\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/test_ai/lib/python3.11/site-packages/langchain_ollama/chat_models.py:642\u001b[39m, in \u001b[36mChatOllama._chat_stream_with_aggregation\u001b[39m\u001b[34m(self, messages, stop, run_manager, verbose, **kwargs)\u001b[39m\n\u001b[32m    633\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_chat_stream_with_aggregation\u001b[39m(\n\u001b[32m    634\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    635\u001b[39m     messages: List[BaseMessage],\n\u001b[32m   (...)\u001b[39m\u001b[32m    639\u001b[39m     **kwargs: Any,\n\u001b[32m    640\u001b[39m ) -> ChatGenerationChunk:\n\u001b[32m    641\u001b[39m     final_chunk = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m642\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_iterate_over_stream\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    643\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfinal_chunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m:\u001b[49m\n\u001b[32m    644\u001b[39m \u001b[43m            \u001b[49m\u001b[43mfinal_chunk\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/test_ai/lib/python3.11/site-packages/langchain_ollama/chat_models.py:727\u001b[39m, in \u001b[36mChatOllama._iterate_over_stream\u001b[39m\u001b[34m(self, messages, stop, **kwargs)\u001b[39m\n\u001b[32m    720\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_iterate_over_stream\u001b[39m(\n\u001b[32m    721\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    722\u001b[39m     messages: List[BaseMessage],\n\u001b[32m    723\u001b[39m     stop: Optional[List[\u001b[38;5;28mstr\u001b[39m]] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    724\u001b[39m     **kwargs: Any,\n\u001b[32m    725\u001b[39m ) -> Iterator[ChatGenerationChunk]:\n\u001b[32m    726\u001b[39m     is_thinking = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m727\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_resp\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_create_chat_stream\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    728\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mstream_resp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    729\u001b[39m \u001b[43m            \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mChatGenerationChunk\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    730\u001b[39m \u001b[43m                \u001b[49m\u001b[43mmessage\u001b[49m\u001b[43m=\u001b[49m\u001b[43mAIMessageChunk\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    731\u001b[39m \u001b[43m                    \u001b[49m\u001b[43mcontent\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   (...)\u001b[39m\u001b[32m    744\u001b[39m \u001b[43m                \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    745\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/test_ai/lib/python3.11/site-packages/langchain_ollama/chat_models.py:629\u001b[39m, in \u001b[36mChatOllama._create_chat_stream\u001b[39m\u001b[34m(self, messages, stop, **kwargs)\u001b[39m\n\u001b[32m    626\u001b[39m chat_params = \u001b[38;5;28mself\u001b[39m._chat_params(messages, stop, **kwargs)\n\u001b[32m    628\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m chat_params[\u001b[33m\"\u001b[39m\u001b[33mstream\u001b[39m\u001b[33m\"\u001b[39m]:\n\u001b[32m--> \u001b[39m\u001b[32m629\u001b[39m     \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m._client.chat(**chat_params)\n\u001b[32m    630\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    631\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m \u001b[38;5;28mself\u001b[39m._client.chat(**chat_params)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/test_ai/lib/python3.11/site-packages/ollama/_client.py:170\u001b[39m, in \u001b[36mClient._request.<locals>.inner\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    167\u001b[39m   e.response.read()\n\u001b[32m    168\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m ResponseError(e.response.text, e.response.status_code) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m170\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mline\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mr\u001b[49m\u001b[43m.\u001b[49m\u001b[43miter_lines\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    171\u001b[39m \u001b[43m  \u001b[49m\u001b[43mpart\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mjson\u001b[49m\u001b[43m.\u001b[49m\u001b[43mloads\u001b[49m\u001b[43m(\u001b[49m\u001b[43mline\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    172\u001b[39m \u001b[43m  \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43merr\u001b[49m\u001b[43m \u001b[49m\u001b[43m:=\u001b[49m\u001b[43m \u001b[49m\u001b[43mpart\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43merror\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/test_ai/lib/python3.11/site-packages/httpx/_models.py:929\u001b[39m, in \u001b[36mResponse.iter_lines\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    927\u001b[39m decoder = LineDecoder()\n\u001b[32m    928\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m request_context(request=\u001b[38;5;28mself\u001b[39m._request):\n\u001b[32m--> \u001b[39m\u001b[32m929\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtext\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43miter_text\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    930\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mline\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdecoder\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    931\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mline\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/test_ai/lib/python3.11/site-packages/httpx/_models.py:916\u001b[39m, in \u001b[36mResponse.iter_text\u001b[39m\u001b[34m(self, chunk_size)\u001b[39m\n\u001b[32m    914\u001b[39m chunker = TextChunker(chunk_size=chunk_size)\n\u001b[32m    915\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m request_context(request=\u001b[38;5;28mself\u001b[39m._request):\n\u001b[32m--> \u001b[39m\u001b[32m916\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbyte_content\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43miter_bytes\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    917\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtext_content\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecoder\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbyte_content\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    918\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunker\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext_content\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/test_ai/lib/python3.11/site-packages/httpx/_models.py:897\u001b[39m, in \u001b[36mResponse.iter_bytes\u001b[39m\u001b[34m(self, chunk_size)\u001b[39m\n\u001b[32m    895\u001b[39m chunker = ByteChunker(chunk_size=chunk_size)\n\u001b[32m    896\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m request_context(request=\u001b[38;5;28mself\u001b[39m._request):\n\u001b[32m--> \u001b[39m\u001b[32m897\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mraw_bytes\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43miter_raw\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    898\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdecoded\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecoder\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mraw_bytes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    899\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunker\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdecoded\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/test_ai/lib/python3.11/site-packages/httpx/_models.py:951\u001b[39m, in \u001b[36mResponse.iter_raw\u001b[39m\u001b[34m(self, chunk_size)\u001b[39m\n\u001b[32m    948\u001b[39m chunker = ByteChunker(chunk_size=chunk_size)\n\u001b[32m    950\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m request_context(request=\u001b[38;5;28mself\u001b[39m._request):\n\u001b[32m--> \u001b[39m\u001b[32m951\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mraw_stream_bytes\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    952\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_num_bytes_downloaded\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mraw_stream_bytes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    953\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunker\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mraw_stream_bytes\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/test_ai/lib/python3.11/site-packages/httpx/_client.py:153\u001b[39m, in \u001b[36mBoundSyncStream.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    152\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__iter__\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> typing.Iterator[\u001b[38;5;28mbytes\u001b[39m]:\n\u001b[32m--> \u001b[39m\u001b[32m153\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_stream\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    154\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/test_ai/lib/python3.11/site-packages/httpx/_transports/default.py:127\u001b[39m, in \u001b[36mResponseStream.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    125\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__iter__\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> typing.Iterator[\u001b[38;5;28mbytes\u001b[39m]:\n\u001b[32m    126\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m map_httpcore_exceptions():\n\u001b[32m--> \u001b[39m\u001b[32m127\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpart\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_httpcore_stream\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    128\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpart\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/test_ai/lib/python3.11/site-packages/httpcore/_sync/connection_pool.py:407\u001b[39m, in \u001b[36mPoolByteStream.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    405\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m    406\u001b[39m     \u001b[38;5;28mself\u001b[39m.close()\n\u001b[32m--> \u001b[39m\u001b[32m407\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m exc \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/test_ai/lib/python3.11/site-packages/httpcore/_sync/connection_pool.py:403\u001b[39m, in \u001b[36mPoolByteStream.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    401\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__iter__\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> typing.Iterator[\u001b[38;5;28mbytes\u001b[39m]:\n\u001b[32m    402\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m403\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpart\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_stream\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    404\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpart\u001b[49m\n\u001b[32m    405\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/test_ai/lib/python3.11/site-packages/httpcore/_sync/http11.py:342\u001b[39m, in \u001b[36mHTTP11ConnectionByteStream.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    340\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m ShieldCancellation():\n\u001b[32m    341\u001b[39m     \u001b[38;5;28mself\u001b[39m.close()\n\u001b[32m--> \u001b[39m\u001b[32m342\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m exc\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/test_ai/lib/python3.11/site-packages/httpcore/_sync/http11.py:334\u001b[39m, in \u001b[36mHTTP11ConnectionByteStream.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    332\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    333\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m Trace(\u001b[33m\"\u001b[39m\u001b[33mreceive_response_body\u001b[39m\u001b[33m\"\u001b[39m, logger, \u001b[38;5;28mself\u001b[39m._request, kwargs):\n\u001b[32m--> \u001b[39m\u001b[32m334\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_connection\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_receive_response_body\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    335\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\n\u001b[32m    336\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m    337\u001b[39m     \u001b[38;5;66;03m# If we get an exception while streaming the response,\u001b[39;00m\n\u001b[32m    338\u001b[39m     \u001b[38;5;66;03m# we want to close the response (and possibly the connection)\u001b[39;00m\n\u001b[32m    339\u001b[39m     \u001b[38;5;66;03m# before raising that exception.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/test_ai/lib/python3.11/site-packages/httpcore/_sync/http11.py:203\u001b[39m, in \u001b[36mHTTP11Connection._receive_response_body\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    200\u001b[39m timeout = timeouts.get(\u001b[33m\"\u001b[39m\u001b[33mread\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    202\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m203\u001b[39m     event = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_receive_event\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    204\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(event, h11.Data):\n\u001b[32m    205\u001b[39m         \u001b[38;5;28;01myield\u001b[39;00m \u001b[38;5;28mbytes\u001b[39m(event.data)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/test_ai/lib/python3.11/site-packages/httpcore/_sync/http11.py:233\u001b[39m, in \u001b[36mHTTP11Connection._receive_event\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    230\u001b[39m         msg = \u001b[33m\"\u001b[39m\u001b[33mServer disconnected without sending a response.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    231\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m RemoteProtocolError(msg)\n\u001b[32m--> \u001b[39m\u001b[32m233\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_h11_state\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreceive_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    234\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    235\u001b[39m     \u001b[38;5;66;03m# mypy fails to narrow the type in the above if statement above\u001b[39;00m\n\u001b[32m    236\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m event\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/test_ai/lib/python3.11/site-packages/h11/_connection.py:352\u001b[39m, in \u001b[36mConnection.receive_data\u001b[39m\u001b[34m(self, data)\u001b[39m\n\u001b[32m    343\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Data that has been received, but not yet processed, represented as\u001b[39;00m\n\u001b[32m    344\u001b[39m \u001b[33;03m    a tuple with two elements, where the first is a byte-string containing\u001b[39;00m\n\u001b[32m    345\u001b[39m \u001b[33;03m    the unprocessed data itself, and the second is a bool that is True if\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    348\u001b[39m \u001b[33;03m    See :ref:`switching-protocols` for discussion of why you'd want this.\u001b[39;00m\n\u001b[32m    349\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m    350\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28mbytes\u001b[39m(\u001b[38;5;28mself\u001b[39m._receive_buffer), \u001b[38;5;28mself\u001b[39m._receive_buffer_closed)\n\u001b[32m--> \u001b[39m\u001b[32m352\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mreceive_data\u001b[39m(\u001b[38;5;28mself\u001b[39m, data: \u001b[38;5;28mbytes\u001b[39m) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    353\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Add data to our internal receive buffer.\u001b[39;00m\n\u001b[32m    354\u001b[39m \n\u001b[32m    355\u001b[39m \u001b[33;03m    This does not actually do any processing on the data, just stores\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    389\u001b[39m \n\u001b[32m    390\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m    391\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m data:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "total_time_all_models = {}\n",
    "overall_times = []\n",
    "\n",
    "for model in models:\n",
    "    print(f\"Тестирование модели: {model}\")\n",
    "    llm_model = ChatOllama(model=model)\n",
    "    \n",
    "    total_time = test_model(llm_model, questions, model)\n",
    "    total_time_all_models[model] = total_time\n",
    "    overall_times.append({\n",
    "        \"model\": model,\n",
    "        \"total_time\": total_time\n",
    "    })\n",
    "    print(f\"Общее время для модели {model}: {total_time} секунд\")\n",
    "\n",
    "total_time_overall = sum(total_time_all_models.values())\n",
    "print(f\"Общее время на все вопросы для всех моделей: {total_time_overall} секунд\")\n",
    "\n",
    "overall_times_df = pd.DataFrame(overall_times)\n",
    "overall_times_df.to_csv(\"overall_times.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12e38960-34ee-4ad9-9d12-c4f98e77c061",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b11f470-a693-448f-883f-2f2389c89994",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
